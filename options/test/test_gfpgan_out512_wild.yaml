# same settings with the fos-real test
name: gfpgan1.4  # just keep the name
model_type: GFPGANModel

num_gpu: 1 # set num_gpu: 0 for cpu mode
save_suffix: ''
# FaceRestoreHelper
helper:
  upscale_factor: 1
  save_ext: png
  use_parse: True

# path
path:
  # the benchmark used GFPGAN model v1.4
  results_path: results/gfpgan/vfhq/vfhq_test_interval1_LR_Blind_128
  logs_root: results/gfpgan/vfhq
  pretrained_model: weights/GFPGANv1.4.pth
  pretrained_model_url: ~

dataset:
  name: test_wild
  type: FosSingleImageDataset
  dataroot_lq: data/vfhq/interval1_LR_Blind_128
  meta_info_file: data/vfhq/interval1_LR_Blind.pathlist
  aligned: false
  only_center_face: ~

  # for data normalization
  mean: [0.5, 0.5, 0.5]
  std: [0.5, 0.5, 0.5]
  face_size: 512
  # metrics: [niqe, serfiq, maniqa]

# network structures
network_g:
  type: GFPGANv1Clean
  out_size: 512
  num_style_feat: 512
  channel_multiplier: 2
  decoder_load_path: ~
  fix_decoder: false
  num_mlp: 8
  input_is_latent: true
  different_w: true
  narrow: 1
  sft_half: true