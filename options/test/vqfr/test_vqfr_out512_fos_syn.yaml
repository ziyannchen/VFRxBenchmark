name: vqfr_fos_syn
# model
model_type: VQFRModel
fidelity_ratio: 0.1

num_gpu: 1 # set num_gpu: 0 for cpu mode
save_suffix: ''
# FaceRestoreHelper
helper:
  upscale_factor: 1
  save_ext: png
  use_parse: True

datasets:
  props:
    mean: [0.5, 0.5, 0.5]
    std: [0.5, 0.5, 0.5]
    face_size: 512

  test_syn:
    name: fos_syn
    type: FosPairedImageDataset
    dataroot_lq: data/fos_syn/fos_syn
    dataroot_gt: data/fos_syn/fos_syn_gt
    meta_info_file: data/fos_syn/fos_syn.pathlist
    aligned: true

    metrics: [psnr, ssim, lpips, serfiq, niqe, maniqa, fid_folder]

# network related (e.g. structures
network_g:
  # The model same with the released version from CodeFormer
  type: VQFRv2

  # the benchmark used the default setting
  base_channels: 64
  channel_multipliers: [1, 2, 2, 4, 4, 8]
  num_enc_blocks: 2
  use_enc_attention: True
  num_dec_blocks: 2
  use_dec_attention: True
  code_dim: 256
  inpfeat_dim: 32
  align_opt: {
      'cond_channels': 32,
      'deformable_groups': 4
  }
  code_selection_mode: 'Predict'  # Predict/Nearest
  quantizer_opt: {
      'type': 'L2VectorQuantizer',
      'num_code': 1024,
      'code_dim': 256,
      'spatial_size': [16, 16]
  }

# path
path:
  # model
  pretrain_network: VQFR_v2.pth
  pretrain_model_url: https://github.com/TencentARC/VQFR/releases/download/v2.0.0/VQFR_v2.pth