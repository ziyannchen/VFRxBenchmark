name: vqfr_fos_real
# model
model_type: VQFRModel
fidelity_ratio: 0.1

num_gpu: 1 # set num_gpu: 0 for cpu mode
save_suffix: ''
# FaceRestoreHelper
helper:
  upscale_factor: 1
  save_ext: png
  use_parse: True

datasets:
  mean: [0.5, 0.5, 0.5]
  std: [0.5, 0.5, 0.5]
  face_size: 512

  name: fos_real
  type: FosSingleImageDataset
  dataroot_lq: data/fos_real/fos_real_aligned
  meta_info_file: data/fos_real/fos_real.pathlist
  aligned: true

  # metrics: [niqe, brisque, fid_folder, serfiq, sddfiqa, faceqnet, maniqa]

# path
path:
  # model
  pretrained_network: ~
  pretrained_model_url: https://github.com/TencentARC/VQFR/releases/download/v2.0.0/VQFR_v2.pth

network_g:
  # The model same with the released version from CodeFormer
  type: VQFRv2

  # the benchmark used the default setting
  base_channels: 64
  channel_multipliers: [1, 2, 2, 4, 4, 8]
  num_enc_blocks: 2
  use_enc_attention: True
  num_dec_blocks: 2
  use_dec_attention: True
  code_dim: 256
  inpfeat_dim: 32
  align_opt: {
      'cond_channels': 32,
      'deformable_groups': 4
  }
  code_selection_mode: 'Predict'  # Predict/Nearest
  quantizer_opt: {
      'type': 'L2VectorQuantizer',
      'num_code': 1024,
      'code_dim': 256,
      'spatial_size': [16, 16]
  }